# ==================== 数据库配置 ====================

# Redis配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# MySQL配置
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=chatuser
MYSQL_PASSWORD=ChangeMe123!
MYSQL_DATABASE=chatdb

# Elasticsearch配置
ES_HOST=localhost
ES_PORT=9200
ES_USERNAME=elastic
ES_PASSWORD=password01
ES_KNOWLEDGE_INDEX=kb_vector_store  # 通用知识库索引(用于ESRetriever)
ES_CONVERSATION_INDEX=conversation_history  # 对话历史索引
ES_CYPHER_INDEX=qa_system  # Neo4j Cypher示例索引(用于Neo4jIntentParser生成Cypher查询)
# 注意: qa_system索引包含字段 question(问题), answer(Cypher查询), embedding_question(1024维向量)
# 运行 old/neo4j_code/documents/es_embedding.py 生成该索引

# Neo4j配置
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=ChangeMe123!

# ==================== LLM基础配置 ====================

# LLM API配置(默认配置)
LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
LLM_API_KEY=sk-f9f3209599454a49ba6fb4f36c3c0434
LLM_MODEL_NAME=deepseek-v3

# ==================== LLM模型分场景配置 ====================

# 意图识别LLM配置
LLM_MODEL_INTENT_RECOGNITION_MODEL=deepseek-v3
LLM_MODEL_INTENT_RECOGNITION_TEMPERATURE=0
LLM_MODEL_INTENT_RECOGNITION_MAX_TOKENS=500

# Cypher生成LLM配置
LLM_MODEL_CYPHER_GENERATION_MODEL=deepseek-v3
LLM_MODEL_CYPHER_GENERATION_TEMPERATURE=0
LLM_MODEL_CYPHER_GENERATION_MAX_TOKENS=500

# 对话生成LLM配置
LLM_MODEL_CHAT_GENERATION_MODEL=qwq-32b
LLM_MODEL_CHAT_GENERATION_TEMPERATURE=0
LLM_MODEL_CHAT_GENERATION_MAX_TOKENS=4000

# 摘要生成LLM配置
LLM_MODEL_SUMMARY_GENERATION_MODEL=deepseek-v3
LLM_MODEL_SUMMARY_GENERATION_TEMPERATURE=0
LLM_MODEL_SUMMARY_GENERATION_MAX_TOKENS=200

# 知识匹配LLM配置
LLM_MODEL_KNOWLEDGE_MATCHING_MODEL=deepseek-v3
LLM_MODEL_KNOWLEDGE_MATCHING_TEMPERATURE=0
LLM_MODEL_KNOWLEDGE_MATCHING_MAX_TOKENS=1000

# ==================== 提示词配置 ====================

# 系统提示词
PROMPT_SYSTEM_PROMPT="你是一个专业的AI助手，致力于为用户提供准确、有用的回答。

请遵循以下原则：
1. 基于提供的参考知识进行回答，确保准确性
2. 如果参考知识不足以回答问题，请诚实地说明
3. 保持回答简洁明了，避免冗余
4. 使用友好、专业的语气
5. 如果涉及专业术语，请适当解释

回答时请：
- 优先使用参考知识中的信息
- 如需引用，请标注来源
- 对不确定的内容，明确表达不确定性"

# 意图识别提示词
PROMPT_INTENT_RECOGNITION_PROMPT="你是一个意图识别专家。请分析用户的查询，判断其意图类型。

可能的意图类型：
1. es_query - 通用知识查询（法规、标准、概念等）
2. neo4j_query - 图数据库查询（关系、路径、层级、网络拓扑等）
3. hybrid_query - 混合查询

用户查询: {query}

请判断意图类型，并给出置信度（0-1）。
只输出JSON格式: {\"intent_type\": \"xxx\", \"confidence\": 0.xx}"

# Neo4j Cypher生成提示词
PROMPT_NEO4J_CYPHER_GENERATION_PROMPT="你是一个Neo4j Cypher查询生成专家。

数据库包含以下节点类型:
- Netname: 网络节点 (属性: name, netSecretLevel, networkType)
- Unit: 单位节点 (属性: name, unitType)
- SYSTEM: 系统节点 (属性: name, systemSecretLevel)
- Safeproduct: 安全产品 (属性: name, safeProductCount)
- Totalintegrations: 集成商 (属性: name, totalIntegrationLevel)

关系类型:
- UNIT_NET, OPERATIONUNIT_NET, OVERUNIT_NET
- SOFTWAREUNIT_SYSTEM, SYSTEM_NET, SECURITY_NET

参考以下示例:
{examples}

用户问题: {query}

请生成一个Cypher查询来回答这个问题。
要求:
1. 只输出Cypher查询,不要有任何解释
2. Cypher必须是可执行的
3. 参考示例的格式和模式
4. 确保返回有意义的结果

Cypher查询:"

# 知识增强提示词模板
PROMPT_KNOWLEDGE_ENHANCED_PROMPT_TEMPLATE="{system_prompt}

以下是历史对话，请基于上下文回答用户的新问题。

--- 历史对话开始 ---
{history}
--- 历史对话结束 ---

--- 相关知识 ---
{knowledge}
--- 知识结束 ---

用户: {query}

助手:"

# 摘要生成提示词
PROMPT_SUMMARY_GENERATION_PROMPT="请为以下对话生成简洁的摘要（不超过50字）：

{conversation}

摘要:"

# 知识匹配提示词
PROMPT_KNOWLEDGE_MATCHING_PROMPT="请分析LLM的回答，找出其中引用的知识点，并与提供的知识库进行匹配。

LLM回答:
{llm_output}

知识库:
{knowledge_base}

请返回匹配的知识ID列表（JSON格式）。
格式: {\"matched_ids\": [\"id1\", \"id2\", ...]}"

# ==================== Embedding配置 ====================

EMBEDDING_API_URL=http://localhost:8000/embed
EMBEDDING_MODEL_NAME=bge-large-zh-v1.5
EMBEDDING_DIMENSION=1024

# ==================== 应用配置 ====================

# 服务器配置
APP_HOST=0.0.0.0
APP_PORT=8011
APP_DEBUG=False

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
